# ğŸ“Š Pipeline de ETL com Apache Airflow e Dashboard Streamlit

Este projeto implementa um **pipeline completo de ETL** usando **Apache Airflow** para extraÃ§Ã£o e carga de dados, **PostgreSQL** como banco de dados e **Streamlit** para visualizaÃ§Ã£o interativa. Todo o projeto Ã© **containerizado com Docker**.

## ğŸ— Arquitetura do Projeto

1. **Airflow** baixa dados de COVID-19 e insere no PostgreSQL.
2. **PostgreSQL** armazena os dados processados.
3. **Streamlit** lÃª os dados e exibe grÃ¡ficos interativos.
4. Tudo orquestrado com **Docker Compose**.

## ğŸ“‚ Estrutura do Projeto
```
airflow_streamlit_pipeline/
â”‚â”€â”€ airflow/                # ConfiguraÃ§Ã£o do Apache Airflow
â”‚   â”œâ”€â”€ dags/               # DAGs do Airflow
â”‚   â”‚   â”œâ”€â”€ etl_covid.py    # DAG de ETL
â”‚   â”œâ”€â”€ Dockerfile          # Dockerfile do Airflow
â”‚â”€â”€ streamlit/              # App de visualizaÃ§Ã£o
â”‚   â”œâ”€â”€ app.py              # CÃ³digo do Streamlit
â”‚   â”œâ”€â”€ Dockerfile          # Dockerfile do Streamlit
â”‚â”€â”€ docker-compose.yml      # ConfiguraÃ§Ã£o do Docker Compose
â”‚â”€â”€ .env                    # VariÃ¡veis de ambiente
```

## ğŸš€ Como Executar
### 1ï¸âƒ£ Clonar o repositÃ³rio
```bash
git clone https://github.com/seu-usuario/airflow_streamlit_pipeline.git
cd airflow_streamlit_pipeline
```

### 2ï¸âƒ£ Subir os containers
```bash
docker-compose up -d
```

### 3ï¸âƒ£ Acessar os serviÃ§os
- **Airflow**: [http://localhost:8080](http://localhost:8080)
- **Streamlit Dashboard**: [http://localhost:8501](http://localhost:8501)

## ğŸ›  Tecnologias Utilizadas
- **Apache Airflow**: OrquestraÃ§Ã£o de ETL
- **PostgreSQL**: Banco de dados
- **Streamlit**: Dashboard interativo
- **Docker & Docker Compose**: ContainerizaÃ§Ã£o
